{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a265330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Testing RNN Model\n",
      "==================================================\n",
      "\n",
      "[Adaptive Fold 1] Training RNN...\n",
      "[Adaptive Fold 1] RMSE=20.569, MAE=20.322\n",
      "\n",
      "[Adaptive Fold 2] Training RNN...\n",
      "[Adaptive Fold 2] RMSE=16.994, MAE=15.528\n",
      "\n",
      "[Adaptive Fold 3] Training RNN...\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000228B5DC07C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[Adaptive Fold 3] RMSE=7.476, MAE=6.008\n",
      "\n",
      "[Baseline Fold 1] Training RNN...\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000228BC36FC40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[Baseline Fold 1] RMSE=12.022, MAE=10.958\n",
      "\n",
      "[Baseline Fold 2] Training RNN...\n",
      "[Baseline Fold 2] RMSE=11.920, MAE=9.470\n",
      "\n",
      "[Baseline Fold 3] Training RNN...\n",
      "[Baseline Fold 3] RMSE=61.070, MAE=56.888\n",
      "\n",
      "[Baseline Fold 4] Training RNN...\n",
      "[Baseline Fold 4] RMSE=23.583, MAE=20.549\n",
      "\n",
      "[Baseline Fold 5] Training RNN...\n",
      "[Baseline Fold 5] RMSE=51.625, MAE=46.337\n",
      "\n",
      "==================================================\n",
      "Testing LSTM Model\n",
      "==================================================\n",
      "\n",
      "[Adaptive Fold 1] Training LSTM...\n",
      "[Adaptive Fold 1] RMSE=13.805, MAE=13.607\n",
      "\n",
      "[Adaptive Fold 2] Training LSTM...\n",
      "[Adaptive Fold 2] RMSE=14.959, MAE=12.939\n",
      "\n",
      "[Adaptive Fold 3] Training LSTM...\n",
      "[Adaptive Fold 3] RMSE=17.333, MAE=16.867\n",
      "\n",
      "[Baseline Fold 1] Training LSTM...\n",
      "[Baseline Fold 1] RMSE=10.895, MAE=10.027\n",
      "\n",
      "[Baseline Fold 2] Training LSTM...\n",
      "[Baseline Fold 2] RMSE=11.644, MAE=9.474\n",
      "\n",
      "[Baseline Fold 3] Training LSTM...\n",
      "[Baseline Fold 3] RMSE=52.501, MAE=48.821\n",
      "\n",
      "[Baseline Fold 4] Training LSTM...\n",
      "[Baseline Fold 4] RMSE=23.546, MAE=20.620\n",
      "\n",
      "[Baseline Fold 5] Training LSTM...\n",
      "[Baseline Fold 5] RMSE=55.891, MAE=51.889\n",
      "\n",
      "==================================================\n",
      "Testing GRU Model\n",
      "==================================================\n",
      "\n",
      "[Adaptive Fold 1] Training GRU...\n",
      "[Adaptive Fold 1] RMSE=12.003, MAE=11.887\n",
      "\n",
      "[Adaptive Fold 2] Training GRU...\n",
      "[Adaptive Fold 2] RMSE=14.842, MAE=12.733\n",
      "\n",
      "[Adaptive Fold 3] Training GRU...\n",
      "[Adaptive Fold 3] RMSE=10.509, MAE=9.599\n",
      "\n",
      "[Baseline Fold 1] Training GRU...\n",
      "[Baseline Fold 1] RMSE=10.575, MAE=9.725\n",
      "\n",
      "[Baseline Fold 2] Training GRU...\n",
      "[Baseline Fold 2] RMSE=11.880, MAE=9.611\n",
      "\n",
      "[Baseline Fold 3] Training GRU...\n",
      "[Baseline Fold 3] RMSE=47.449, MAE=42.805\n",
      "\n",
      "[Baseline Fold 4] Training GRU...\n",
      "[Baseline Fold 4] RMSE=23.333, MAE=19.979\n",
      "\n",
      "[Baseline Fold 5] Training GRU...\n",
      "[Baseline Fold 5] RMSE=49.496, MAE=46.251\n",
      "\n",
      "==================================================\n",
      "Testing LINEAR Model\n",
      "==================================================\n",
      "\n",
      "[Adaptive Fold 1] Training LINEAR...\n",
      "[Adaptive Fold 1] RMSE=19.655, MAE=17.674\n",
      "\n",
      "[Adaptive Fold 2] Training LINEAR...\n",
      "[Adaptive Fold 2] RMSE=10.705, MAE=8.737\n",
      "\n",
      "[Adaptive Fold 3] Training LINEAR...\n",
      "[Adaptive Fold 3] RMSE=20.747, MAE=18.202\n",
      "\n",
      "[Baseline Fold 1] Training LINEAR...\n",
      "[Baseline Fold 1] RMSE=11.772, MAE=10.273\n",
      "\n",
      "[Baseline Fold 2] Training LINEAR...\n",
      "[Baseline Fold 2] RMSE=13.165, MAE=10.994\n",
      "\n",
      "[Baseline Fold 3] Training LINEAR...\n",
      "[Baseline Fold 3] RMSE=38.834, MAE=33.079\n",
      "\n",
      "[Baseline Fold 4] Training LINEAR...\n",
      "[Baseline Fold 4] RMSE=33.312, MAE=28.025\n",
      "\n",
      "[Baseline Fold 5] Training LINEAR...\n",
      "[Baseline Fold 5] RMSE=53.327, MAE=48.113\n",
      "\n",
      "================================================================================\n",
      "MODEL COMPARISON SUMMARY\n",
      "================================================================================\n",
      "\n",
      "RNN Results:\n",
      "------------------------------\n",
      "Adaptive CV - Avg RMSE: 15.013, Avg MAE: 13.953\n",
      "Baseline CV - Avg RMSE: 32.044, Avg MAE: 28.840\n",
      "\n",
      "LSTM Results:\n",
      "------------------------------\n",
      "Adaptive CV - Avg RMSE: 15.366, Avg MAE: 14.471\n",
      "Baseline CV - Avg RMSE: 30.895, Avg MAE: 28.166\n",
      "\n",
      "GRU Results:\n",
      "------------------------------\n",
      "Adaptive CV - Avg RMSE: 12.452, Avg MAE: 11.406\n",
      "Baseline CV - Avg RMSE: 28.547, Avg MAE: 25.674\n",
      "\n",
      "LINEAR Results:\n",
      "------------------------------\n",
      "Adaptive CV - Avg RMSE: 17.036, Avg MAE: 14.871\n",
      "Baseline CV - Avg RMSE: 30.082, Avg MAE: 26.097\n",
      "\n",
      "Best Model: GRU\n",
      "\n",
      "Drift Dates:\n",
      "['09/07/2015', '21/06/2016', '05/06/2017', '17/05/2018', '02/05/2019', '15/04/2020', '17/09/2021', '13/10/2022', '21/03/2024']\n"
     ]
    }
   ],
   "source": [
    "# ต้องมาก่อนการใช้ TensorFlow ทุกอย่าง!\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# ===== ตั้งค่าความเสถียรและ reproducibility =====\n",
    "os.environ['PYTHONHASHSEED'] = '42'\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# ปิด multi-threading ของ TensorFlow\n",
    "tf.config.threading.set_intra_op_parallelism_threads(1)\n",
    "tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "\n",
    "from typing import Tuple, List\n",
    "import pandas as pd\n",
    "from scipy.stats import ks_2samp, mannwhitneyu\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, GRU, SimpleRNN, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# Preprocess data\n",
    "df = pd.read_csv(\"AAPL_10yr_data.csv\", parse_dates=[\"Date\"])\n",
    "df['Date'] = pd.to_datetime(df['Date'], format=\"%d/%m/%Y\")\n",
    "df = df.sort_values(\"Date\")\n",
    "\n",
    "# Feature engineering\n",
    "df['Return'] = df['Close'].pct_change()\n",
    "df['Volatility'] = df['Close'].rolling(10).std()\n",
    "df['Price_Diff'] = df['High'] - df['Low']\n",
    "df['Volume_Log'] = np.log1p(df['Volume'])\n",
    "\n",
    "# Drop NaN หลัง rolling\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "X = df[['Return', 'Volatility', 'Price_Diff', 'Volume_Log']]\n",
    "y = df['Close']\n",
    "\n",
    "class SequenceGenerator:\n",
    "    \"\"\"\n",
    "    สร้าง sequence data สำหรับ RNN-based models\n",
    "    \"\"\"\n",
    "    def __init__(self, sequence_length: int = 30):\n",
    "        self.sequence_length = sequence_length\n",
    "        self.scaler_X = StandardScaler()\n",
    "        self.scaler_y = StandardScaler()\n",
    "        \n",
    "    def create_sequences(self, X: pd.DataFrame, y: pd.Series, fit_scalers: bool = True):\n",
    "        \"\"\"\n",
    "        สร้าง sequence data สำหรับ RNN-based models\n",
    "        \"\"\"\n",
    "        # Scale features\n",
    "        if fit_scalers:\n",
    "            X_scaled = self.scaler_X.fit_transform(X)\n",
    "            y_scaled = self.scaler_y.fit_transform(y.values.reshape(-1, 1)).flatten()\n",
    "        else:\n",
    "            X_scaled = self.scaler_X.transform(X)\n",
    "            y_scaled = self.scaler_y.transform(y.values.reshape(-1, 1)).flatten()\n",
    "        \n",
    "        # Create sequences\n",
    "        X_seq, y_seq = [], []\n",
    "        for i in range(self.sequence_length, len(X_scaled)):\n",
    "            X_seq.append(X_scaled[i-self.sequence_length:i])\n",
    "            y_seq.append(y_scaled[i])\n",
    "        \n",
    "        return np.array(X_seq), np.array(y_seq)\n",
    "    \n",
    "    def inverse_transform_y(self, y_scaled):\n",
    "        \"\"\"\n",
    "        แปลงค่า y กลับเป็นสเกลเดิม\n",
    "        \"\"\"\n",
    "        return self.scaler_y.inverse_transform(y_scaled.reshape(-1, 1)).flatten()\n",
    "\n",
    "class RNNRegressor:\n",
    "    \"\"\"\n",
    "    Universal RNN Regressor ที่รองรับ RNN, LSTM, และ GRU\n",
    "    \"\"\"\n",
    "    def __init__(self, model_type: str = 'LSTM', sequence_length: int = 30, \n",
    "                 units: int = 50, dropout_rate: float = 0.2, \n",
    "                 learning_rate: float = 0.001, epochs: int = 100, \n",
    "                 batch_size: int = 32, verbose: int = 0):\n",
    "        \n",
    "        self.model_type = model_type.upper()\n",
    "        self.sequence_length = sequence_length\n",
    "        self.units = units\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.verbose = verbose\n",
    "        self.model = None\n",
    "        self.seq_generator = SequenceGenerator(sequence_length)\n",
    "        \n",
    "        # ตรวจสอบว่า model_type ถูกต้อง\n",
    "        if self.model_type not in ['RNN', 'LSTM', 'GRU']:\n",
    "            raise ValueError(\"model_type must be 'RNN', 'LSTM', or 'GRU'\")\n",
    "        \n",
    "    def _get_layer_type(self):\n",
    "        \"\"\"\n",
    "        เลือก layer type ตาม model_type\n",
    "        \"\"\"\n",
    "        if self.model_type == 'RNN':\n",
    "            return SimpleRNN\n",
    "        elif self.model_type == 'LSTM':\n",
    "            return LSTM\n",
    "        elif self.model_type == 'GRU':\n",
    "            return GRU\n",
    "        \n",
    "    def _build_model(self, input_shape):\n",
    "        \"\"\"\n",
    "        สร้างโมเดล RNN ตาม model_type\n",
    "        \"\"\"\n",
    "        LayerType = self._get_layer_type()\n",
    "        \n",
    "        model = Sequential([\n",
    "            LayerType(self.units, return_sequences=True, input_shape=input_shape),\n",
    "            Dropout(self.dropout_rate),\n",
    "            LayerType(self.units // 2, return_sequences=False),\n",
    "            Dropout(self.dropout_rate),\n",
    "            Dense(25, activation='relu'),\n",
    "            Dense(1)\n",
    "        ])\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=Adam(learning_rate=self.learning_rate),\n",
    "            loss='mse',\n",
    "            metrics=['mae']\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def fit(self, X: pd.DataFrame, y: pd.Series):\n",
    "        \"\"\"\n",
    "        Train RNN model\n",
    "        \"\"\"\n",
    "        # Create sequences\n",
    "        X_seq, y_seq = self.seq_generator.create_sequences(X, y, fit_scalers=True)\n",
    "        \n",
    "        if len(X_seq) == 0:\n",
    "            raise ValueError(\"Not enough data to create sequences\")\n",
    "        \n",
    "        # Build model\n",
    "        self.model = self._build_model((X_seq.shape[1], X_seq.shape[2]))\n",
    "        \n",
    "        # Early stopping\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor='loss',\n",
    "            patience=10,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "        \n",
    "        # Train model\n",
    "        self.model.fit(\n",
    "            X_seq, y_seq,\n",
    "            epochs=self.epochs,\n",
    "            batch_size=self.batch_size,\n",
    "            callbacks=[early_stopping],\n",
    "            verbose=self.verbose\n",
    "        )\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Make predictions\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model not fitted yet\")\n",
    "        \n",
    "        # Create sequences (don't fit scalers)\n",
    "        X_seq, _ = self.seq_generator.create_sequences(\n",
    "            X, pd.Series([0] * len(X)), fit_scalers=False\n",
    "        )\n",
    "        \n",
    "        if len(X_seq) == 0:\n",
    "            # Return predictions for available data points\n",
    "            return np.array([])\n",
    "        \n",
    "        # Predict\n",
    "        y_pred_scaled = self.model.predict(X_seq, verbose=0)\n",
    "        \n",
    "        # Inverse transform\n",
    "        y_pred = self.seq_generator.inverse_transform_y(y_pred_scaled)\n",
    "        \n",
    "        return y_pred\n",
    "\n",
    "class LinearRegressionModel:\n",
    "    \"\"\"\n",
    "    Linear Regression model with standardization\n",
    "    \"\"\"\n",
    "    def __init__(self, fit_intercept: bool = True):\n",
    "        self.fit_intercept = fit_intercept\n",
    "        self.scaler_X = StandardScaler()\n",
    "        self.scaler_y = StandardScaler()\n",
    "        self.model = LinearRegression(fit_intercept=fit_intercept)\n",
    "        self.is_fitted = False\n",
    "        \n",
    "    def fit(self, X: pd.DataFrame, y: pd.Series):\n",
    "        \"\"\"\n",
    "        Train Linear Regression model\n",
    "        \"\"\"\n",
    "        # Scale features\n",
    "        X_scaled = self.scaler_X.fit_transform(X)\n",
    "        y_scaled = self.scaler_y.fit_transform(y.values.reshape(-1, 1)).flatten()\n",
    "        \n",
    "        # Train model\n",
    "        self.model.fit(X_scaled, y_scaled)\n",
    "        self.is_fitted = True\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Make predictions\n",
    "        \"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"Model not fitted yet\")\n",
    "        \n",
    "        # Scale features\n",
    "        X_scaled = self.scaler_X.transform(X)\n",
    "        \n",
    "        # Predict\n",
    "        y_pred_scaled = self.model.predict(X_scaled)\n",
    "        \n",
    "        # Inverse transform\n",
    "        y_pred = self.scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()\n",
    "        \n",
    "        return y_pred\n",
    "\n",
    "class DriftPointDetector:\n",
    "    \"\"\"\n",
    "    ตรวจจับจุดเกิด concept drift ในข้อมูล time series ด้วยการใช้\n",
    "    หลายวิธีทดสอบและป้องกันการจับ pattern ที่ผิดพลาด\n",
    "    \"\"\"\n",
    "    def __init__(self, window_size: int = 120, threshold: float = 0.001, \n",
    "                 step_size: int = 30, min_effect_size: float = 0.3,\n",
    "                 stability_window: int = 60, confirmation_tests: int = 2): \n",
    "        self.window_size = window_size # ขนาดหน้าต่างสำหรับการตรวจจับ drift\n",
    "        self.threshold = threshold # ค่าความสำคัญสำหรับการทดสอบ\n",
    "        self.step_size = step_size # ขนาด step สำหรับการเลื่อนหน้าต่าง\n",
    "        self.min_effect_size = min_effect_size # ขนาดผลกระทบขั้นต่ำที่ต้องการ\n",
    "        self.stability_window = stability_window # หน้าต่างเสถียรภาพก่อนการตรวจจับ drift\n",
    "        self.confirmation_tests = confirmation_tests # จำนวนการทดสอบยืนยันที่ต้องผ่านก่อนที่จะถือว่าเป็น drift\n",
    "        self.drift_points_: List[int] = [] # จุดที่ตรวจจับได้\n",
    "\n",
    "    def _calculate_effect_size(self, window1: pd.Series, window2: pd.Series) -> float:\n",
    "        \"\"\"คำนวณขนาดผลกระทบ (Cohen's d)\"\"\"\n",
    "        mean1, mean2 = window1.mean(), window2.mean()\n",
    "        std1, std2 = window1.std(), window2.std()\n",
    "        \n",
    "        pooled_std = np.sqrt(((len(window1) - 1) * std1**2 + (len(window2) - 1) * std2**2) / \n",
    "                           (len(window1) + len(window2) - 2))\n",
    "        \n",
    "        if pooled_std == 0:\n",
    "            return 0\n",
    "        \n",
    "        return abs(mean1 - mean2) / pooled_std\n",
    "\n",
    "    def _test_multiple_statistics(self, window1: pd.DataFrame, window2: pd.DataFrame) -> Tuple[int, float]:\n",
    "        \"\"\"ทดสอบหลายวิธีเพื่อยืนยัน drift\"\"\"\n",
    "        passed_tests = 0 # จำนวนการทดสอบที่ผ่าน\n",
    "        min_p_value = 1.0 # ค่าพื้นฐานสำหรับ p-value\n",
    "        \n",
    "        for col in window1.columns:\n",
    "            col_tests = 0\n",
    "            col_p_values = []\n",
    "            \n",
    "            # Test 1: Kolmogorov-Smirnov test\n",
    "            try:\n",
    "                stat, p_value = ks_2samp(window1[col], window2[col])\n",
    "                col_p_values.append(p_value)\n",
    "                if p_value < self.threshold:\n",
    "                    col_tests += 1\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            # Test 2: Mann-Whitney U test\n",
    "            try:\n",
    "                stat, p_value = mannwhitneyu(window1[col], window2[col], alternative='two-sided')\n",
    "                col_p_values.append(p_value)\n",
    "                if p_value < self.threshold:\n",
    "                    col_tests += 1\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            # Test 3: Effect size check\n",
    "            effect_size = self._calculate_effect_size(window1[col], window2[col]) # ขนาดผลกระทบ\n",
    "            if effect_size > self.min_effect_size: # ขนาดผลกระทบที่ต้องการ\n",
    "                col_tests += 1 # เพิ่มการทดสอบขนาดผลกระทบ\n",
    "            \n",
    "            if col_p_values:\n",
    "                min_p_value = min(min_p_value, min(col_p_values))\n",
    "            \n",
    "            if col_tests >= self.confirmation_tests: # ต้องผ่านการทดสอบยืนยันขั้นต่ำ\n",
    "                passed_tests += 1\n",
    "        \n",
    "        return passed_tests, min_p_value # ค่าพื้นฐานสำหรับ p-value\n",
    "\n",
    "    def _check_stability_before_drift(self, X: pd.DataFrame, position: int) -> bool:\n",
    "        \"\"\"ตรวจสอบว่าช่วงก่อนหน้ามีเสถียรภาพหรือไม่\"\"\"\n",
    "        if position < self.stability_window + self.window_size:\n",
    "            return True\n",
    "        \n",
    "        stable_start = position - self.stability_window - self.window_size\n",
    "        stable_end = position - self.window_size\n",
    "        stable_window = X.iloc[stable_start:stable_end]\n",
    "        \n",
    "        mid_point = len(stable_window) // 2\n",
    "        stable_part1 = stable_window.iloc[:mid_point]\n",
    "        stable_part2 = stable_window.iloc[mid_point:]\n",
    "        \n",
    "        for col in X.columns:\n",
    "            if len(stable_part1) > 0 and len(stable_part2) > 0:\n",
    "                try:\n",
    "                    stat, p_value = ks_2samp(stable_part1[col], stable_part2[col])\n",
    "                    if p_value < self.threshold * 10:\n",
    "                        return False\n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "        return True\n",
    "\n",
    "    def _remove_pattern_drifts(self, drift_candidates: List[Tuple[int, float]]) -> List[int]:\n",
    "        \"\"\"กรองจุด drift ที่อาจเป็น pattern\"\"\"\n",
    "        if len(drift_candidates) < 3: # ถ้ามีน้อยกว่า 3 จุด ไม่ต้องกรอง\n",
    "            return [pos for pos, _ in drift_candidates]\n",
    "        \n",
    "        drift_candidates.sort(key=lambda x: x[0]) # เรียงตามตำแหน่ง\n",
    "        \n",
    "        intervals = []\n",
    "        for i in range(1, len(drift_candidates)):\n",
    "            interval = drift_candidates[i][0] - drift_candidates[i-1][0]\n",
    "            intervals.append(interval)\n",
    "        \n",
    "        filtered_drifts = []\n",
    "        if len(intervals) > 1:\n",
    "            interval_std = np.std(intervals)\n",
    "            interval_mean = np.mean(intervals)\n",
    "            \n",
    "            if interval_std / interval_mean < 0.3: \n",
    "                drift_candidates.sort(key=lambda x: x[1])\n",
    "                keep_count = max(1, len(drift_candidates) // 3)\n",
    "                filtered_drifts = [pos for pos, _ in drift_candidates[:keep_count]]\n",
    "            else:\n",
    "                filtered_drifts = [pos for pos, _ in drift_candidates]\n",
    "        else:\n",
    "            filtered_drifts = [pos for pos, _ in drift_candidates]\n",
    "        \n",
    "        final_drifts = []\n",
    "        min_distance = self.window_size * 2\n",
    "        \n",
    "        for pos in sorted(filtered_drifts):\n",
    "            if not final_drifts or pos - final_drifts[-1] >= min_distance:\n",
    "                final_drifts.append(pos)\n",
    "        \n",
    "        return final_drifts\n",
    "\n",
    "    def detect(self, X: pd.DataFrame) -> List[int]:\n",
    "        self.drift_points_ = []\n",
    "        n = len(X)\n",
    "        drift_candidates = []\n",
    "        \n",
    "        for i in range(self.window_size, n - self.window_size, self.step_size):\n",
    "            if not self._check_stability_before_drift(X, i):\n",
    "                continue\n",
    "            \n",
    "            window1 = X.iloc[i - self.window_size:i]\n",
    "            window2 = X.iloc[i:i + self.window_size]\n",
    "            \n",
    "            passed_tests, min_p_value = self._test_multiple_statistics(window1, window2)\n",
    "            \n",
    "            if passed_tests >= 1:\n",
    "                drift_candidates.append((i, min_p_value))\n",
    "        \n",
    "        self.drift_points_ = self._remove_pattern_drifts(drift_candidates)\n",
    "        \n",
    "        return self.drift_points_\n",
    "\n",
    "class AdaptiveFoldGenerator:\n",
    "    \"\"\"\n",
    "    สร้าง train/test folds โดยแบ่งตาม drift points ที่ตรวจจับได้\n",
    "    \"\"\"\n",
    "    def __init__(self, min_fold_size: int = 120, test_ratio: float = 0.2):\n",
    "        self.min_fold_size = min_fold_size\n",
    "        self.test_ratio = test_ratio\n",
    "\n",
    "    def split(self, X: pd.DataFrame, drift_points: List[int]) -> List[Tuple[np.ndarray, np.ndarray]]:\n",
    "        folds = []\n",
    "        points = [0] + drift_points + [len(X)]\n",
    "        \n",
    "        for i in range(len(points) - 1):\n",
    "            start, end = points[i], points[i + 1]\n",
    "            fold_length = end - start\n",
    "\n",
    "            if fold_length < self.min_fold_size:\n",
    "                continue\n",
    "\n",
    "            split = int(start + (1 - self.test_ratio) * fold_length)\n",
    "            train_idx = np.arange(start, split)\n",
    "            test_idx = np.arange(split, end)\n",
    "\n",
    "            # เพิ่มขนาดขั้นต่ำสำหรับ RNN models\n",
    "            if len(train_idx) > 100 and len(test_idx) > 50: # ขนาดขั้นต่ำสำหรับ train/test\n",
    "                folds.append((train_idx, test_idx))\n",
    "        \n",
    "        return folds\n",
    "\n",
    "class DriftAdaptiveTimeSeriesCV:\n",
    "    \"\"\"\n",
    "    ทำ cross-validation โดยใช้ fold ที่แบ่งตาม drift points สำหรับ RNN models และ Linear Regression\n",
    "    \"\"\"\n",
    "    def __init__(self, model_type: str = 'LSTM', model_params: dict = None):\n",
    "        self.model_type = model_type.upper()\n",
    "        self.model_params = model_params or {\n",
    "            'sequence_length': 30,\n",
    "            'units': 50,\n",
    "            'dropout_rate': 0.3,\n",
    "            'learning_rate': 0.001,\n",
    "            'epochs': 50,\n",
    "            'batch_size': 32,\n",
    "            'verbose': 0\n",
    "        }\n",
    "\n",
    "    def run(self, X: pd.DataFrame, y: pd.Series, drift_points: List[int]) -> Tuple[List[float], List[float]]:\n",
    "        fold_gen = AdaptiveFoldGenerator()\n",
    "        metrics_rmse, metrics_mae = [], []\n",
    "\n",
    "        folds = fold_gen.split(X, drift_points)\n",
    "        if not folds:\n",
    "            print(\"Warning: No valid folds generated by AdaptiveFoldGenerator!\")\n",
    "            return [], []\n",
    "\n",
    "        for i, (train_idx, test_idx) in enumerate(folds):\n",
    "            print(f\"\\n[Adaptive Fold {i+1}] Training {self.model_type}...\")\n",
    "            \n",
    "            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "            # สร้างโมเดล ใหม่สำหรับแต่ละ fold\n",
    "            if self.model_type in ['RNN', 'LSTM', 'GRU']:\n",
    "                model = RNNRegressor(model_type=self.model_type, **self.model_params)\n",
    "            elif self.model_type == 'LINEAR':\n",
    "                model = LinearRegressionModel(**self.model_params)\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown model type: {self.model_type}\")\n",
    "            \n",
    "            try:\n",
    "                model.fit(X_train, y_train)\n",
    "                y_pred = model.predict(X_test)\n",
    "                \n",
    "                # Align predictions with actual values (สำหรับ RNN models เนื่องจาก sequence length)\n",
    "                if self.model_type in ['RNN', 'LSTM', 'GRU']:\n",
    "                    if len(y_pred) > 0:\n",
    "                        y_test_aligned = y_test.iloc[model.seq_generator.sequence_length:]\n",
    "                        y_test_aligned = y_test_aligned.iloc[:len(y_pred)]\n",
    "                        \n",
    "                        rmse = np.sqrt(mean_squared_error(y_test_aligned, y_pred))\n",
    "                        mae = mean_absolute_error(y_test_aligned, y_pred)\n",
    "                    else:\n",
    "                        print(f\"[Adaptive Fold {i+1}] No predictions generated (insufficient data)\")\n",
    "                        continue\n",
    "                else:  # สำหรับ Linear Regression\n",
    "                    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "                    mae = mean_absolute_error(y_test, y_pred)\n",
    "                \n",
    "                print(f\"[Adaptive Fold {i+1}] RMSE={rmse:.3f}, MAE={mae:.3f}\")\n",
    "                \n",
    "                metrics_rmse.append(rmse)\n",
    "                metrics_mae.append(mae)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"[Adaptive Fold {i+1}] Error: {e}\")\n",
    "                continue\n",
    "\n",
    "        return metrics_rmse, metrics_mae\n",
    "\n",
    "class BaselineTimeSeriesCV:\n",
    "    \"\"\"\n",
    "    ทำ cross-validation แบบ TimeSeriesSplit ปกติ สำหรับ RNN models และ Linear Regression\n",
    "    \"\"\"\n",
    "    def __init__(self, model_type: str = 'LSTM', model_params: dict = None, n_splits: int = 5):\n",
    "        self.model_type = model_type.upper()\n",
    "        self.model_params = model_params or {\n",
    "            'sequence_length': 30,\n",
    "            'units': 50,\n",
    "            'dropout_rate': 0.3,\n",
    "            'learning_rate': 0.001,\n",
    "            'epochs': 50,\n",
    "            'batch_size': 32,\n",
    "            'verbose': 0\n",
    "        }\n",
    "        self.n_splits = n_splits\n",
    "\n",
    "    def run(self, X: pd.DataFrame, y: pd.Series) -> Tuple[List[float], List[float]]:\n",
    "        tscv = TimeSeriesSplit(n_splits=self.n_splits)\n",
    "        metrics_rmse, metrics_mae = [], []\n",
    "\n",
    "        for i, (train_idx, test_idx) in enumerate(tscv.split(X)):\n",
    "            print(f\"\\n[Baseline Fold {i+1}] Training {self.model_type}...\")\n",
    "            \n",
    "            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "            # สร้างโมเดล ใหม่สำหรับแต่ละ fold\n",
    "            if self.model_type in ['RNN', 'LSTM', 'GRU']:\n",
    "                model = RNNRegressor(model_type=self.model_type, **self.model_params)\n",
    "            elif self.model_type == 'LINEAR':\n",
    "                model = LinearRegressionModel(**self.model_params)\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown model type: {self.model_type}\")\n",
    "            \n",
    "            try:\n",
    "                model.fit(X_train, y_train)\n",
    "                y_pred = model.predict(X_test)\n",
    "                \n",
    "                # Align predictions with actual values (สำหรับ RNN models)\n",
    "                if self.model_type in ['RNN', 'LSTM', 'GRU']:\n",
    "                    if len(y_pred) > 0:\n",
    "                        y_test_aligned = y_test.iloc[model.seq_generator.sequence_length:]\n",
    "                        y_test_aligned = y_test_aligned.iloc[:len(y_pred)]\n",
    "                        \n",
    "                        rmse = np.sqrt(mean_squared_error(y_test_aligned, y_pred))\n",
    "                        mae = mean_absolute_error(y_test_aligned, y_pred)\n",
    "                    else:\n",
    "                        print(f\"[Baseline Fold {i+1}] No predictions generated (insufficient data)\")\n",
    "                        continue\n",
    "                else:  # สำหรับ Linear Regression\n",
    "                    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "                    mae = mean_absolute_error(y_test, y_pred)\n",
    "                \n",
    "                print(f\"[Baseline Fold {i+1}] RMSE={rmse:.3f}, MAE={mae:.3f}\")\n",
    "                \n",
    "                metrics_rmse.append(rmse)\n",
    "                metrics_mae.append(mae)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"[Baseline Fold {i+1}] Error: {e}\")\n",
    "                continue\n",
    "\n",
    "        return metrics_rmse, metrics_mae\n",
    "\n",
    "class ModelComparison:\n",
    "    \"\"\"\n",
    "    เปรียบเทียบประสิทธิภาพของ RNN, LSTM, GRU และ Linear Regression\n",
    "    \"\"\"\n",
    "    def __init__(self, rnn_params: dict = None, linear_params: dict = None):\n",
    "        self.rnn_params = rnn_params or {\n",
    "            'sequence_length': 30,\n",
    "            'units': 50,\n",
    "            'dropout_rate': 0.3,\n",
    "            'learning_rate': 0.001,\n",
    "            'epochs': 50,\n",
    "            'batch_size': 32,\n",
    "            'verbose': 0\n",
    "        }\n",
    "        self.linear_params = linear_params or {'fit_intercept': True}\n",
    "        self.models = ['RNN', 'LSTM', 'GRU', 'LINEAR']\n",
    "        \n",
    "    def compare_models(self, X: pd.DataFrame, y: pd.Series, drift_points: List[int]):\n",
    "        \"\"\"\n",
    "        เปรียบเทียบโมเดลทั้งหมดด้วย adaptive CV\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        for model_type in self.models:\n",
    "            print(f\"\\n{'='*50}\")\n",
    "            print(f\"Testing {model_type} Model\")\n",
    "            print(f\"{'='*50}\")\n",
    "            \n",
    "            # เลือกพารามิเตอร์ที่เหมาะสมตามประเภทโมเดล\n",
    "            if model_type == 'LINEAR':\n",
    "                params = self.linear_params\n",
    "            else:\n",
    "                params = self.rnn_params\n",
    "            \n",
    "            # Adaptive CV\n",
    "            drift_cv = DriftAdaptiveTimeSeriesCV(model_type, params)\n",
    "            drift_rmse, drift_mae = drift_cv.run(X, y, drift_points)\n",
    "            \n",
    "            # Baseline CV\n",
    "            baseline_cv = BaselineTimeSeriesCV(model_type, params, n_splits=5)\n",
    "            base_rmse, base_mae = baseline_cv.run(X, y)\n",
    "            \n",
    "            results[model_type] = {\n",
    "                'adaptive_rmse': drift_rmse,\n",
    "                'adaptive_mae': drift_mae,\n",
    "                'baseline_rmse': base_rmse,\n",
    "                'baseline_mae': base_mae\n",
    "            }\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def print_summary(self, results: dict):\n",
    "        \"\"\"\n",
    "        พิมพ์สรุปผลลัพธ์การเปรียบเทียบ\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"MODEL COMPARISON SUMMARY\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        for model_type in self.models:\n",
    "            if model_type in results:\n",
    "                print(f\"\\n{model_type} Results:\")\n",
    "                print(\"-\" * 30)\n",
    "                \n",
    "                # Adaptive results\n",
    "                if results[model_type]['adaptive_rmse'] and results[model_type]['adaptive_mae']:\n",
    "                    avg_rmse = np.mean(results[model_type]['adaptive_rmse'])\n",
    "                    avg_mae = np.mean(results[model_type]['adaptive_mae'])\n",
    "                    print(f\"Adaptive CV - Avg RMSE: {avg_rmse:.3f}, Avg MAE: {avg_mae:.3f}\")\n",
    "                else:\n",
    "                    print(\"Adaptive CV - No valid results\")\n",
    "                \n",
    "                # Baseline results\n",
    "                if results[model_type]['baseline_rmse'] and results[model_type]['baseline_mae']:\n",
    "                    avg_rmse = np.mean(results[model_type]['baseline_rmse'])\n",
    "                    avg_mae = np.mean(results[model_type]['baseline_mae'])\n",
    "                    print(f\"Baseline CV - Avg RMSE: {avg_rmse:.3f}, Avg MAE: {avg_mae:.3f}\")\n",
    "                else:\n",
    "                    print(\"Baseline CV - No valid results\")\n",
    "        \n",
    "        # หาโมเดลที่ดีที่สุด\n",
    "        best_model = self._find_best_model(results)\n",
    "        if best_model:\n",
    "            print(f\"\\nBest Model: {best_model}\")\n",
    "    \n",
    "    def _find_best_model(self, results: dict):\n",
    "        \"\"\"\n",
    "        หาโมเดลที่ดีที่สุดจากผลลัพธ์\n",
    "        \"\"\"\n",
    "        best_model = None\n",
    "        best_score = float('inf')\n",
    "        \n",
    "        for model_type in self.models:\n",
    "            if model_type in results:\n",
    "                # ใช้ adaptive RMSE เป็นเกณฑ์\n",
    "                if results[model_type]['adaptive_rmse']:\n",
    "                    avg_rmse = np.mean(results[model_type]['adaptive_rmse'])\n",
    "                    if avg_rmse < best_score:\n",
    "                        best_score = avg_rmse\n",
    "                        best_model = model_type\n",
    "                # ถ้าไม่มี adaptive results ใช้ baseline\n",
    "                elif results[model_type]['baseline_rmse']:\n",
    "                    avg_rmse = np.mean(results[model_type]['baseline_rmse'])\n",
    "                    if avg_rmse < best_score:\n",
    "                        best_score = avg_rmse\n",
    "                        best_model = model_type\n",
    "        \n",
    "        return best_model\n",
    "\n",
    "# ตัวอย่างการใช้งานที่ถูกต้อง\n",
    "if __name__ == \"__main__\":\n",
    "    # 1) Detect drift points\n",
    "    detector = DriftPointDetector(\n",
    "        window_size=120, # ขนาดหน้าต่างสำหรับการตรวจจับ drift\n",
    "        threshold=0.001,  \n",
    "        step_size=30, # ขนาด step สำหรับการเลื่อนหน้าต่าง\n",
    "        min_effect_size=0.3, # ขนาดผลกระทบขั้นต่ำที่ต้องการ\n",
    "        stability_window=60,    # หน้าต่างเสถียรภาพก่อนการตรวจจับ drift\n",
    "        confirmation_tests=2 # จำนวนการทดสอบยืนยันที่ต้องผ่านก่อนที่จะถือว่าเป็น drift\n",
    "    )\n",
    "    drift_points = detector.detect(X)\n",
    "    \n",
    "    # 2) เปรียบเทียบโมเดลทั้งหมด\n",
    "    rnn_params = {\n",
    "        'sequence_length': 30,\n",
    "        'units': 50, # จำนวนหน่วยใน LSTM/GRU\n",
    "        'dropout_rate': 0.3, # อัตราการ dropout\n",
    "        'learning_rate': 0.001, # อัตราการเรียนรู้\n",
    "        'epochs': 30, # จำนวน epoch สำหรับการฝึก\n",
    "        'batch_size': 32, # ขนาด batch สำหรับการฝึก\n",
    "        'verbose': 0 # ระดับการแสดงผล (0 = ไม่มีการแสดงผล)\n",
    "    }\n",
    "    \n",
    "    linear_params = {'fit_intercept': True}\n",
    "    \n",
    "    comparator = ModelComparison(rnn_params=rnn_params, linear_params=linear_params)\n",
    "    results = comparator.compare_models(X, y, drift_points)\n",
    "    comparator.print_summary(results)\n",
    "\n",
    "    # แปลง drift point index เป็นวันที่แบบ วัน/เดือน/ปี\n",
    "    drift_dates_formatted = df.iloc[drift_points]['Date'].dt.strftime('%d/%m/%Y').tolist()\n",
    "    print(\"\\nDrift Dates:\")\n",
    "    print(drift_dates_formatted)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
